{
    "contents" : "---\ntitle: \"HW7\"\noutput: html_document\n---\n###Wei Chen, 5207679\n### Q6.2\nUsing the information in Example 6.1. Construct the 95% Bonferroni simultaneous intervals for the components of the mean difference vector $\\delta$. Compare the lengths of these intervals with those of te simultaneous intervals constrcuted n the example.      \n\nSolution:\n```{r}\nURL='http://users.stat.umn.edu/~guxxx192/courses/wichern_data/t6-1.dat'\nwastewater=read.table(URL, col.names=c('comml.BOD','comml.SS','state.BOD','state.SS'))\nDiff<-wastewater[,c(1,2)]-wastewater[,c(3,4)]\ncolnames(Diff)<- c('diff.BOD','diff.SS')\ndbar<- colMeans(Diff)\nSd<-cov(Diff)\nn<-nrow(Diff)\np<-ncol(Diff)\nmu0<-c(0,0)\nalpha<-1-0.95\nradius<-qt(alpha/(2*p),df=n-1,lower.tail=FALSE)\nprint(lower_bon_w<- dbar-radius*sqrt(diag(Sd)/n))\nprint(upper_bon_w<-dbar+radius*sqrt(diag(Sd)/n))\n```\nWe find that 95% T^2^ simultaneous  intervals is wider than 95% Bonferroni simultaneous intervals.     \n\n### Q6.3\nThe data corresponding to sample 8 in Table 6.1 seem unusually large. Remove sample 8. Construct a joint 95% confidence region for the mean difference vector $\\delta$ and the 95% Bonferroni simultaneous intervals for the components of the mean difference vector. Are the results consistent with a test of H~0~: $\\delta$? Discuss. DOes the 'outlier' make a difference in the analysis of these data?      \nSolution:\n```{r}\nnewDiff<-Diff[-8,]\nnew_dbar<-colMeans(newDiff)\nnewSd<- cov(newDiff)\nnew_n<-nrow(newDiff)\nnew_p<-ncol(newDiff)\nradius_bon_new_w<-qt(alpha/(2*new_p),df=new_n-1, lower.tail=FALSE)\nprint(lower_bon_new_w<- new_dbar- radius_bon_new_w*sqrt(diag(newSd)/new_n))\nprint(upper_bon_new_w<- new_dbar+ radius_bon_new_w*sqrt(diag(newSd)/new_n))\nradius_T2_new_w<-sqrt(new_p*(new_n-1)/(new_n-new_p)*qf(alpha, df1=new_p, df2=new_n-new_p,lower.tail=FALSE))\nprint(lower_T2_new_w<- new_dbar-radius_T2_new_w*sqrt(diag(newSd)/new_n))\nprint(upper_T2_new_w<- new_dbar+radius_T2_new_w*sqrt(diag(newSd)/new_n))\n```\n\nAfter removing the sample 8, the simultaneous intervals of both T^2^ and Bonferroni no longer cover [0,0]. So we need to reject the null hypothesis and yes, the \"outlier\" Does make a difference during the analysis. \n\n### Q6.4\nRefer to Example 6.1\n(a)Redo the analysis in Example 6.1 after transforming the pairs of observations to ln(BOD) and ln(SS)      \n(b)Construct the 95% Bonferroni simultaneous intervals for the components of the mean vector $\\delta$ of transformed variables       \n(c)Discuss any possible violation of the assumption of a bivariate normal distribution for the difference vectors of transformed observations.      \n\nSolution:   \n(a)\n```{r}\nwastewater<-log(wastewater)\nDiff<-wastewater[,c(1,2)]-wastewater[,c(3,4)]\ndbar<- colMeans(Diff)\nSd<-cov(Diff)\nn<-nrow(Diff)\np<-ncol(Diff)\nmu0<-c(0,0)\nalpha<-1-0.95\nradius_T2<- sqrt(p*(n-1)/(n-p)*qf(alpha, df1=p,df2=n-p, lower.tail=FALSE))\nprint(lower_T2<-dbar-radius_T2*sqrt(diag(Sd)/n))\nprint(upper_T2<-dbar+radius_T2*sqrt(diag(Sd)/n))\n```\n(b)\n```{r}\nradius_bon<-qt(alpha/(2*p),df=n-1,lower.tail=FALSE)\nprint(lower_bon_w<- dbar-radius_bon*sqrt(diag(Sd)/n))\nprint(upper_bon_w<-dbar+radius_bon*sqrt(diag(Sd)/n))\n```\n(c)\n```{r}\nlibrary(car)\ncolnames(Diff)<- c('diff.lnBOD','diff.lnSS')\n#dev.off()\nscatterplot(diff.lnBOD ~diff.lnSS, data=Diff, smoother=FALSE, reg.line=FALSE)\n```\n\nNote that scatterplot of paired variables is not elliptical shape which implies it violates bivariate normality.     \n### Q6.9\nUsing the constrast matrix C in (6-13), verify the relationships d~j~=Cx~j~, $\\bar{d}$=C$\\bar{x}$, and S~d~=CSC' in (6-14)    \n\n\nSolution:     \n(1)\nFirst we prove $\\left[ \\begin{array}{cc} d_{1} & \\dots & d_{j}& \\dots & d_{N} \\end{array} \\right]$=$D_{p*N}$=$C_{p*2p}$$X_{2p*N}$= $C_{p*2p}$$\\left[ \\begin{array}{c} X^{treat1}_{p*N} \\\\ X^{treat2}_{p*N} \\end{array} \\right]$, which means       \n\\[\n\\left[ \\begin{array}{cc} d_{1} & \\dots & d_{j}& \\dots & d_{N} \\end{array} \\right] = \\begin{bmatrix}\n    1 & 0 & \\dots & 0 &-1 & 0 &\\dots & 0 \\\\\n    0 & 1 & \\dots & 0 &0 &-1 & \\dots  & 0 \\\\\n    \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\vdots &\\ddots &\\vdots \\\\\n    0 & 0 & \\dots & 1 & 0 & 0 &\\dots  & -1\n\\end{bmatrix}\n \\times \\left[ \\begin{array}{cc} x_{1} & \\dots & x_{j}& \\dots & x_{N} \\end{array} \\right]\n, x_{j} = \n\\begin{bmatrix}\nx^{treat1}_{1j}\\\\\nx^{treat1}_{2j}\\\\\n\\vdots \\\\\nx^{treat1}_{pj}\\\\\nx^{treat2}_{1j}\\\\\n\\vdots \\\\\nx^{treat2}_{pj}\n\\end{bmatrix}\n\\]\n(2)       \n\\[ \\bar{d}=\\frac{1}{N} \\sum_{j}^{N} Cx_{j} =C(\\frac{1}{N} \\sum_{j}^{N} x_{j})= C \\bar{x}\\] \n(3)\n\\[ S_{d}=cov(D)=cov(CX)=Ccov(S)C'=CSC' \\]\n      \n### Q6.11\nA likelihood argument provides additional support for pooling the two independent sample covraince matrices to estimate a common covariance matrix in the case of two normal populations. Give the likelihood function, L($\\mu_{1}$,$\\mu_{2}$,$\\Sigma$), for two independent samples of sizes n~1~ and n~2~ from N~p~($\\mu_{1}$,$\\Sigma$) and N~p~($\\mu_{2}$,$\\Sigma$) populations, repectively. Show that this likelihood is maximized by the choices $\\hat{\\mu_{1}}$=$\\bar{x_{1}}$, $\\hat{\\mu_{2}}$=$\\bar{x_{2}}$ and $\\hat{\\Sigma}$= $\\frac{1}{n_{1}+n_{2}}$[$(n_{1}-1)S_{1}+(n_{2}-1)S_{2}$]= ($\\frac{n_{1}+n_{2}-2}{n_{1}+n_{2}}$)$S_{pooled}$         \n\nSolution:  \n\n\\[\n\\begin{aligned}\n&L(\\mu_{1},\\mu_{2},\\Sigma) \\\\\n&=Pr(X_{1}|\\mu_{1}, \\Sigma) \\times Pr(X_{2}|\\mu_{2},\\Sigma)\\\\\n&=\\frac{1}{(2\\pi)^{n_{1}p/2} |\\Sigma|^{n_{1}/2}} exp(-\\frac{1}{2} tr[\\Sigma^{-1}(\\sum_{i=1}^{n_{1}}(x_{1i}-\\bar{x_{1}})(x_{1i}-\\bar{x_{1}})') ] )\\times exp(\\frac{1}{2}n_{1}(\\bar{x_{1}}-\\mu_{1})'\\Sigma^{-1}(\\bar{x_{1}}-\\mu_{1})) \\\\\n&\\times \\frac{1}{(2\\pi)^{n_{2}p/2} |\\Sigma|^{n_{2}/2}} exp(-\\frac{1}{2}  tr[\\Sigma^{-1}(\\sum_{i=1}^{n_{2}}(x_{2i}-\\bar{x_{2}})(x_{2i}-\\bar{x_{2}})') ] )\\times exp(\\frac{1}{2}n_{2}(\\bar{x_{2}}-\\mu_{2})'\\Sigma^{-1}(\\bar{x_{2}}-\\mu_{2}))\n\\end{aligned}\n\\]\nIn order to maximize $exp(\\frac{1}{2}n_{1}(\\bar{x_{1}}-\\mu_{1})'\\Sigma^{-1}(\\bar{x_{1}}-\\mu_{1})) \\times exp(\\frac{1}{2}n_{2}(\\bar{x_{2}}-\\mu_{2})'\\Sigma^{-1}(\\bar{x_{2}}-\\mu_{2}))$ï¼Œwe need to minimize  $n_{1}(\\bar{x_{1}}-\\mu_{1})'\\Sigma^{-1}(\\bar{x_{1}}-\\mu_{1})) + n_{2}(\\bar{x_{2}}-\\mu_{2})'\\Sigma^{-1}(\\bar{x_{2}}-\\mu_{2}))$. Since $\\Sigma_{-1}$ is a positive definite, $n_{1}(\\bar{x_{1}}-\\mu_{1})'\\Sigma^{-1}(\\bar{x_{1}}-\\mu_{1})) >= 0$ and $n_{2}(\\bar{x_{2}}-\\mu_{2})'\\Sigma^{-1}(\\bar{x_{2}}-\\mu_{2})) >=0$. The likelihood is maximized with respect to $\\mu_{1}, \\mu_{2}$ at $\\mu_{1}=\\bar{x_{1}}, \\mu_{2}=\\bar{x_{2}}$.     \nIt remains to maximize \n\\[\n\\begin{aligned}\n&L(\\mu_{1},\\mu_{2},\\Sigma) \\\\\n&=\\frac{1}{(2\\pi)^{n_{1}p/2} |\\Sigma|^{n_{1}/2}} exp(-\\frac{1}{2} tr[\\Sigma^{-1}(\\sum_{i=1}^{n_{1}}(x_{1i}-\\bar{x_{1}})(x_{1i}-\\bar{x_{1}})') ] )\\\\\n&\\times \\frac{1}{(2\\pi)^{n_{2}p/2} |\\Sigma|^{n_{2}/2}} exp(-\\frac{1}{2}  tr[\\Sigma^{-1}(\\sum_{i=1}^{n_{2}}(x_{2i}-\\bar{x_{2}})(x_{2i}-\\bar{x_{2}})') ] )\n\\end{aligned}\n\\]\n By Result 4.10 with $b=(n_{1}+n_{2})/2$ and $B=  \\sum_{i=1}^{n_{1}}(x_{1i}-\\bar{x_{1}})(x_{1i}-\\bar{x_{1}})'+\n\\sum_{i=1}^{n_{2}}(x_{2i}-\\bar{x_{2}})(x_{2i}-\\bar{x_{2}})'\n=(n_{1}+1)S_{1}+(n_{2}+1)S_{2}$, the maximum occurs at $\\hat{\\Sigma}\n= (1/2b)B=$ $\\frac{1}{n_{1}+n_{2}}$$[(n_{1}-1)S_{1}+(n_{2}-1)S_{2}]$$= (\\frac{n_{1}+n_{2}-2}{n_{1}+n_{2}})$$S_{pooled}$.\n\n\n\n",
    "created" : 1459626302303.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2260860549",
    "id" : "E01A0C7F",
    "lastKnownWriteTime" : 1459722270,
    "path" : "~/Documents/MultiAnaly/HW7/HW7/Assign7.Rmd",
    "project_path" : "Assign7.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "type" : "r_markdown"
}